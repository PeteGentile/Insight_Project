{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib, requests, mechanicalsoup\n",
    "import http.cookiejar as cookielib\n",
    "from bs4 import BeautifulSoup\n",
    "import time, traceback, pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparq_from_row(row):\n",
    "    #Calculate the \"sparq\" score for a given row of data\n",
    "    spq = 181.924227 + -4.592111*row[\"Height\"]/30.48 + 0.361056*row[\"Weight\"] - 15.159259*row[\"40 Yard Dash\"] - 45.532307*row[\"10 Yard Split\"] - 5.985102*row[\"3-Cone Drill\"] - 18.731278*row[\"20 Yard Shuttle\"] + 0.252199*row[\"Bench Press\"] + 9.557272*row[\"Broad Jump\"]/30.48 + 1.327290*row[\"Vertical Jump\"]/2.54\n",
    "    return spq\n",
    "\n",
    "def height_string_to_cm(string):\n",
    "    #Convert a height to centimeters and deal with fractions\n",
    "    ft = int(string.split(\"'\")[0])\n",
    "    inches = float(string.split()[1].replace(\"*\", \"\").replace('\"', \"\").replace(\"⅛\", \".125\").replace(\"¼\", \".25\").replace(\"⅜\", \".375\").replace(\"½\", \".5\").replace(\"⅝\",\".625\").replace(\"¾\", \".75\").replace(\"⅞\", \".875\"))\n",
    "    cm = (12*ft + inches) * 2.54\n",
    "    return cm\n",
    "\n",
    "def length_to_in(string):\n",
    "    #Convert length to inches and deal with fractions\n",
    "    length = float(string.replace(\"*\", \"\").replace('\"', \"\").replace(\"⅛\", \".125\").replace(\"¼\", \".25\").replace(\"⅜\", \".375\").replace(\"½\", \".5\").replace(\"⅝\",\".625\").replace(\"¾\", \".75\").replace(\"⅞\", \".875\"))\n",
    "    return length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on height 09:24:15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-672553fe962b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.mockdraftable.com/search?position=ATH&beginYear=1999&endYear=2019&sort=DESC&page=\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"&measurable=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmeasurable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"figure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1360\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stime = time.time()\n",
    "\n",
    "#Define which parameters to keep and which need to be converted\n",
    "measurables = [\"height\", \"weight\", \"wingspan\", \"arms\", \"hands\", \"10yd\", \"40yd\", \"bench\", \"vertical\", \"broad\", \"3cone\", \"20ss\"]\n",
    "needs_conversion = [\"wingspan\", \"arms\", \"hands\", \"vertical\", \"broad\"]\n",
    "\n",
    "#Some of the names on the websites are wrong, so here's a dict of common\n",
    "#errors and their corrections\n",
    "corrections = {\n",
    "    \"r.jay soward\": \"r. jay soward\",\n",
    "    \"johnathan holland\":\"jonathan holland\",\n",
    "    \"terrance toliver\":\"terrence toliver\",\n",
    "    \"odell beckham jr.\" : \"odell beckham, jr.\",\n",
    "    \"mike campanaro\":\"michael campanaro\",\n",
    "    \"t.j.  jones\" : \"t.j. jones\",\n",
    "    \"chris  godwin\":\"chris godwin\",\n",
    "    \"dante pettis\":\"dante pettis \"\n",
    "}\n",
    "\n",
    "#To keep things consistent and readable, we'll use these standard keys for combine measurements\n",
    "key_change = {\n",
    "        \"40yd\":\"40 Yard Dash\",\n",
    "        \"height\":\"Height\",\n",
    "        \"weight\":\"Weight\",\n",
    "        \"vertical\":\"Vertical Jump\",\n",
    "        \"bench\":\"Bench Press\",\n",
    "        \"broad\":\"Broad Jump\",\n",
    "        \"3cone\":\"3-Cone Drill\",\n",
    "        \"20ss\":\"20 Yard Shuttle\",\n",
    "        \"arms\":\"Arm Length\",\n",
    "        \"hands\":\"Hand Size\",\n",
    "        \"10yd\":\"10 Yard Split\",\n",
    "        \"wingspan\":\"Wingspan\"\n",
    "}\n",
    "\n",
    "#We could create an empty dataframe and concat new data to it, but it's faster\n",
    "#to create a dict, append new data to that, then make a dataframe from that dict later.\n",
    "#So let's do that.\n",
    "combines = {}\n",
    "\n",
    "#Loop through mockdraftable's website to get combine measurements\n",
    "for measurable in measurables:\n",
    "    print(\"Working on\", measurable, time.ctime().split()[-2])\n",
    "    alt_measurable = key_change[measurable]\n",
    "    \n",
    "    #There are fewer than 400 pages for each measurement, but let's be safe\n",
    "    for i in range(1,400):\n",
    "        #Open the url for each page needed. If that page does not exist\n",
    "        #(i.e. we've finished that measureable), it'll throw a ValueError, so let's catch that.\n",
    "        try:\n",
    "            url = \"https://www.mockdraftable.com/search?position=ATH&beginYear=1999&endYear=2019&sort=DESC&page=\"+str(i)+\"&measurable=\" + measurable\n",
    "            html = urlopen(url)\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            #Get all the data from the html\n",
    "            for n, h in zip(soup.find_all(\"h5\"), soup.find_all(\"figure\")):\n",
    "                name = n.text.lower()\n",
    "                \n",
    "                #Try to correct names\n",
    "                if name in corrections.keys():\n",
    "                    name = corrections[name]\n",
    "                \n",
    "                #If the player's new, make a new dict entry for them\n",
    "                if not name in combines.keys():\n",
    "                    combines[name] = {}\n",
    "                \n",
    "                #We need the measurement to have been taken\n",
    "                if not h.text == \"?\":\n",
    "                    #Get the value and convert it if needed\n",
    "                    if measurable == \"height\":\n",
    "                        combines[name][alt_measurable] = height_string_to_cm(h.text)\n",
    "                    elif measurable in needs_conversion:\n",
    "                        val_string = h.text.replace(\"*\",\"\").replace(\"lbs\",\"\").replace(\"reps\",\"\").replace(\"s\",\"\")\n",
    "                        combines[name][alt_measurable] = length_to_in(val_string)\n",
    "                    else:\n",
    "                        combines[name][alt_measurable] = float(h.text.replace(\"*\",\"\").replace(\"lbs\",\"\").replace(\"reps\",\"\").replace(\"s\",\"\"))\n",
    "        except ValueError:\n",
    "            break\n",
    "\n",
    "print(\"Done in %0.2f minutes\" %((time.time()-stime)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_with_threshold(probs,thresh = 0.6):\n",
    "    #Make a list of predictions where the threshold is given by the user rather\n",
    "    #than using the standard sklearn threshold of 0.5.\n",
    "    predictions_with_threshold = []\n",
    "    for p in probs:\n",
    "        if p[1] >= thresh:\n",
    "            predictions_with_threshold.append(1)\n",
    "        else:\n",
    "            predictions_with_threshold.append(0)\n",
    "    return np.asarray(predictions_with_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test, pred):\n",
    "    #Given test data and predictions of that data, generate a confusion matrix that\n",
    "    #looks good.\n",
    "    labels = np.asarray(['Below Average', 'Above Average'])\n",
    "    cm = confusion_matrix(labels[test], labels[pred], labels)\n",
    "    fig = plt.figure(figsize = [10,10])\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title('Confusion Matrix of the Classifier', fontsize = 25)\n",
    "    cbar = fig.colorbar(cax)\n",
    "    cbar.ax.tick_params(labelsize=15) \n",
    "    ax.set_xticklabels([''] + list(labels), fontsize = 18)\n",
    "    ax.set_yticklabels([''] + list(labels), fontsize = 18)\n",
    "    ax.xaxis.set_ticks_position(\"bottom\")\n",
    "    plt.xlabel('Predicted', fontsize = 25)\n",
    "    plt.ylabel('True', fontsize = 25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"football_confusion_matrix.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, params, features, targets, cv = 3, scoring = \"precision\", verbose = True, plot=False):\n",
    "    #Perform a grid search and print out useful information about the search\n",
    "    if verbose:\n",
    "        stime = time.time()\n",
    "        print(\"Started\", time.strftime(\"%a, %d %b %Y %H:%M:%S %Z\", time.localtime()))\n",
    "    \n",
    "    #Do the actual grid search\n",
    "    clf = GridSearchCV(model, param_grid = params, scoring = scoring, cv = cv)\n",
    "    clf.fit(features, targets)\n",
    "    \n",
    "    #Get the names of the parameters searched over.\n",
    "    par_names = list(clf.cv_results_[\"params\"][0].keys())\n",
    "    \n",
    "    #Print the parameters of the best classifier.\n",
    "    print(\"Best params:\")\n",
    "    for key, val in clf.best_params_.items():\n",
    "        print(key + \": \", val)\n",
    "    \n",
    "    #But the best classifier might be ties with 2nd best or very close to it, so let's\n",
    "    #look at the pars of all the classifiers sorted on performance.\n",
    "    sorted_pars_scores = [(x,y) for x,y in sorted(zip(clf.cv_results_[\"mean_test_score\"],\\\n",
    "                                                      range(len(clf.cv_results_[\"mean_test_score\"]))),\\\n",
    "                                                  reverse=True)]\n",
    "    \n",
    "    #Assuming a classifier that is searching for Nestimators and learning rates, let's plot\n",
    "    #aa diagnostic heatmap of those parameters\n",
    "    n_ests = []\n",
    "    learning_rates = []\n",
    "    scores = []\n",
    "    \n",
    "    #If verbose, just print out everything\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\" \".join(par_names + [scoring]))\n",
    "        for score, iter_num in sorted_pars_scores:\n",
    "            pars = clf.cv_results_[\"params\"][iter_num]\n",
    "            par_vals = [pars[n] for n in par_names]\n",
    "            learning_rates.append(par_vals[0])\n",
    "            n_ests.append(par_vals[1])\n",
    "            scores.append(100*score)\n",
    "            print(\"%0.2f %d %0.2f\" % (*par_vals, 100*score))\n",
    "            #print(\" \".join([str(val) for val in par_vals + [score]]))\n",
    "        print('Finished in', (time.time()-stime)/60, \"minutes\")\n",
    "        \n",
    "    #If plot, make and plot the heatmap described above\n",
    "    if plot:\n",
    "        plt.scatter(learning_rates, n_ests, c=scores)\n",
    "        plt.xlabel(\"Learning Rate\")\n",
    "        plt.ylabel(\"N_Estimators\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ROC(thresholds, probs, labels):\n",
    "    #To determine the best threshold for prediction, generate a ROC curve and return it.\n",
    "    true_false_positives = []\n",
    "    for thresh in thresholds:\n",
    "        predictions = (probs > thresh)*1\n",
    "        n_false_positives = sum((predictions - labels) == 1)\n",
    "        n_true_positives = sum(((predictions - labels) == 0) & (predictions == 1))\n",
    "        true_false_positives.append([n_true_positives, n_false_positives])\n",
    "    \n",
    "    return np.asarray(true_false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_targets():\n",
    "    #Read in the data scraped from PFR and FO.\n",
    "    pklfile = \"names_dvoas.pkl\"\n",
    "    with open(pklfile, \"rb\") as f:\n",
    "        names,pro_dvoas = pickle.load(f)\n",
    "    \n",
    "    pklfile = \"players.pkl\"\n",
    "    with open(pklfile, \"rb\") as f:\n",
    "        players = pickle.load(f)[0]\n",
    "    \n",
    "    pklfile = \"mockdraftable_stats.pkl\"\n",
    "    with open(pklfile, \"rb\") as f:\n",
    "        combines = pickle.load(f)[0]\n",
    "    \n",
    "    #Convert to dataframes\n",
    "    df = pd.DataFrame.from_dict(players, orient = \"index\")\n",
    "    df[\"name\"] = df[\"name\"].str.lower()\n",
    "    combines_df = pd.DataFrame.from_dict(combines, orient = \"index\")\n",
    "    backup = [names.copy(), pro_dvoas.copy()]\n",
    "    \n",
    "    #Get WRs\n",
    "    wrs = df[df[\"position\"] == \"WR\"]\n",
    "    \n",
    "    #We'll assume stats with values = 0 means missing data, so change 0.00 to nan.\n",
    "    wrs = wrs.where(wrs!=0.00, np.nan)\n",
    "    wrs = wrs.replace(\"Pac-10\", \"Pac-12\")\n",
    "    \n",
    "    #Make a new feature for conference played in \n",
    "    wrs[\"Power 5\"] = wrs[\"conference\"].isin([\"ACC\", \"Big Ten\", \"Big 12\", \"SEC\", \"Pac12\"])**2\n",
    "    wrs = wrs.fillna({\"rush_yds\":0})\n",
    "\n",
    "    #Drop duplicate names\n",
    "    duplicate_names = [\"mike williams\", \"cedrick wilson\", \"steve smith\"]\n",
    "    wrs = wrs.drop_duplicates(subset = [\"name\"], keep=\"first\")\n",
    "    \n",
    "    combine_features = [\"Height\", \"Weight\", \"40 Yard Dash\", \"Vertical Jump\", \"Broad Jump\", \"3-Cone Drill\",\\\n",
    "                        \"20 Yard Shuttle\", \"Bench Press\", 'Arm Length', 'Hand Size', '10 Yard Split', 'Wingspan']\n",
    "    \n",
    "    #Now we need to fill any NaN's in the PFR combine data with mockdraftable data\n",
    "    updated_wrs = wrs.join(combines_df, on = \"name\", rsuffix = \"_mockdraftable\")\n",
    "    for feat in combine_features:\n",
    "        updated_wrs[feat].fillna(updated_wrs[feat + \"_mockdraftable\"])\n",
    "        del updated_wrs[feat + \"_mockdraftable\"]\n",
    "    \n",
    "    \n",
    "    #Next, we're going to deal with remaining missing data by just replacing those values\n",
    "    #with the average value of the stat for a given year. It's a bit messy, but we'll\n",
    "    #do the first iteration outside of a loop to initiate the right dataframes.\n",
    "    old_wr_features = [\"name\", \"draft_year\", \"Height\", \"Weight\", \"40 Yard Dash\", \"Vertical Jump\", \"Broad Jump\", \"3-Cone Drill\", \"20 Yard Shuttle\", \"Bench Press\", \"years_played\", \"games_played\", \"rec\", \"rec_yds\", \"rec_yds_per_rec\", \"rec_td\", 'Arm Length', 'Hand Size', '10 Yard Split', 'Wingspan']\n",
    "    wr_features = [\"Weight\", \"40 Yard Dash\", \"Vertical Jump\", \"Broad Jump\", \"20 Yard Shuttle\", \"years_played\", \"rec\", \"rec_yds\", \"rec_yds_per_rec\", \"rec_td\",'10yd', 'arms', 'hands','wingspan']\n",
    "    cleaned_wrs = updated_wrs[updated_wrs[\"draft_year\"] == 2000]\n",
    "    bad_cols = np.asarray(old_wr_features)[cleaned_wrs[old_wr_features].count()<10]\n",
    "    fillna = cleaned_wrs[old_wr_features].mean()\n",
    "    fillna[bad_cols] = updated_wrs[old_wr_features].mean()[bad_cols]\n",
    "    cleaned_wrs = cleaned_wrs.fillna({i:fillna[i] for i in fillna.index})\n",
    "    \n",
    "    #Then do the rest in a loop.\n",
    "    for year in range(2001,2019):\n",
    "        this_year = wrs[wrs[\"draft_year\"] == year]\n",
    "        bad_cols = np.asarray(old_wr_features)[this_year[old_wr_features].count()<10]\n",
    "        fillna = this_year[old_wr_features].mean()\n",
    "        fillna[bad_cols] = wrs[old_wr_features].mean()[bad_cols]\n",
    "        this_year = this_year.fillna({i:fillna[i] for i in fillna.index})\n",
    "        cleaned_wrs = pd.concat([cleaned_wrs, this_year])\n",
    "    \n",
    "    #Some values from before are in inches. Convert them to cm.\n",
    "    cleaned_wrs.loc[cleaned_wrs[\"Broad Jump\"] < 200, \"Broad Jump\"] *= 2.54\n",
    "    cleaned_wrs.loc[cleaned_wrs[\"Vertical Jump\"] <50, \"Vertical Jump\"] *= 2.54\n",
    "    \n",
    "    features = cleaned_wrs\n",
    "\n",
    "    #Gets all data that have college stats. Makes dvoa = 0 if never in pros.\n",
    "    i=0\n",
    "    names = [n.lower() for n in backup[0]]\n",
    "    dvoas = backup[1].copy()\n",
    "    college_names = [x.lower() for x in cleaned_wrs[\"name\"].to_list()]\n",
    "    final_names = []\n",
    "    played_a_game = {name:1 for name, dvoa in zip(names,pro_dvoas)}\n",
    "    target_dict = {name:dvoa for name, dvoa in zip(names,pro_dvoas)}\n",
    "    \n",
    "    #Names is a list of players who have played in the pros.\n",
    "    #If a player isn't in that list, set the target and played_a_game to values\n",
    "    #that reflect that\n",
    "    for college_name in college_names:\n",
    "        if not college_name in names:\n",
    "            names.append(college_name)\n",
    "            dvoas.append(-2000)\n",
    "            target_dict[college_name] = -2000\n",
    "            played_a_game[college_name] = 0\n",
    "        else:\n",
    "            played_a_game[college_name] = 1\n",
    "    \n",
    "    #This removes any pro player that we somehow don't have college stats for\n",
    "    for key in target_dict.keys():\n",
    "        if not key in college_names:\n",
    "            _ = target_dict.pop(k)\n",
    "            _ = played_a_game.pop(k)\n",
    "\n",
    "    #Just making sure they're in the same order\n",
    "    final_played_a_game = {}\n",
    "    final_targets = {}\n",
    "    for name in college_names:\n",
    "        final_targets[name] = target_dict[name]\n",
    "        final_played_a_game[name] = played_a_game[name]\n",
    "    \n",
    "    #Now make the final targets and return the necessary DFs/data.\n",
    "    targets = []\n",
    "    played_a_game = []\n",
    "    for name in cleaned_wrs[\"name\"]:\n",
    "        targets.append(final_targets[name.lower()])\n",
    "        played_a_game.append(final_played_a_game[name.lower()])\n",
    "\n",
    "    played_a_game = np.asarray(played_a_game)\n",
    "    targets = np.asarray(targets)\n",
    "    #This cuts out players who didn't play in the NFL:\n",
    "    #features = features[targets != -2000]\n",
    "    #targets = targets[targets != -2000]\n",
    "    return cleaned_wrs, features, targets, played_a_game, out_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_wrs, features, targets, played_a_game, df = get_features_targets()\n",
    "\n",
    "#The \"targets\" from above is the player's DVOA.\n",
    "cleaned_wrs[\"DVOA\"] = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the features we'll use from the combine\n",
    "combine_features = ['Height', 'Weight', '40 Yard Dash', 'Vertical Jump', 'Broad Jump', 'Arm Length']\n",
    "\n",
    "#Combine those with relevant college stats.\n",
    "df_subset = cleaned_wrs[combine_features+ [\"rec\", \"rec_yds\", \"rec_td\"]]\n",
    "\n",
    "#Since we tried to take care of any nulls, any remaining nulls can't be\n",
    "#saved, so drop them\n",
    "df_mask = ~df_subset.isnull().any(axis=1)\n",
    "pure_df = cleaned_wrs[df_mask]\n",
    "\n",
    "#Weirdly, Kenny Clark makes the code barf, so just remove him.\n",
    "pure_df = pure_df[(pure_df[\"name\"] != \"kenny clark\").values]\n",
    "\n",
    "#Scale the data. We have to do this before we add features that are one-hot encoded,\n",
    "#like whether or not a player played for a power 5 conference\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pure_df[combine_features + [\"rec\", \"rec_yds\", \"rec_td\"]])\n",
    "\n",
    "#Scale the data and put into a dataframe\n",
    "scaled_features = pd.DataFrame(scaler.transform(pure_df[combine_features + [\"rec\", \"rec_yds\", \"rec_td\"]]),\\\n",
    "                               columns=combine_features + [\"rec\", \"rec_yds\", \"rec_td\"],\\\n",
    "                              index = pure_df.index)\n",
    "\n",
    "#Now insert categorical feature\n",
    "scaled_features.insert(5, \"Power 5\", pure_df[\"Power 5\"].values)\n",
    "\n",
    "#We might want to model how far a player's stats are from the mean stats, so\n",
    "#we'll add those features to give us the option of using them later\n",
    "for feat in combine_features:\n",
    "    scaled_features[feat + \"_dist\"] = (scaled_features[feat]**2)**0.5\n",
    "\n",
    "#Before we oversample, we need to hold out a dataset\n",
    "hold_out_features = scaled_features.sample(frac=0.25, random_state=90, replace = False)\n",
    "hold_out_targets = pure_df.loc[hold_out_features.index][\"DVOA\"]\n",
    "work_features = scaled_features.drop(hold_out_features.index)\n",
    "work_targets = pure_df.drop(hold_out_features.index)\n",
    "work_targets = work_targets[\"DVOA\"]\n",
    "\n",
    "print(len(hold_out_targets), len(work_targets))\n",
    "print(sum(hold_out_targets > 0), len(hold_out_targets))\n",
    "\n",
    "#Let's oversample successes since the dataset is unbalanced. Note that this\n",
    "#needs to be done with replacement.\n",
    "successes = work_targets[work_targets > 0]\n",
    "failures = work_targets[work_targets < 0]\n",
    "oversampled_successes = successes.sample(len(failures), replace = True)\n",
    "\n",
    "#Save this data as a balanced dataset \n",
    "balanced_targets = pd.concat([oversampled_successes, failures])\n",
    "balanced_features = scaled_features.loc[balanced_targets.index]\n",
    "print(sum(balanced_targets > 0), len(balanced_targets))\n",
    "print(len(balanced_targets[balanced_targets > 0])/len(balanced_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rather than try to regress on DVOA, we'll lump players into those with\n",
    "#positive and negative DVOAs. THat's how we'll train our classifier.\n",
    "player_types = np.zeros_like(balanced_targets)\n",
    "player_types[balanced_targets > 0] =1\n",
    "player_types = player_types.astype(int)\n",
    "\n",
    "#Create a list of features depending on whether or not the user wants to use the\n",
    "#_dist features described above or not.\n",
    "dist_setting = \"no dist\"\n",
    "#dist_setting = \"only dist\"\n",
    "#dist_setting = \"both\"\n",
    "\n",
    "\n",
    "if dist_setting == \"both\":\n",
    "    fit_features = ['Power 5','Height', 'Weight',\n",
    "       '40 Yard Dash', 'Vertical Jump', 'Broad Jump',\n",
    "       'Arm Length', 'rec', 'rec_yds', \"rec_td\", 'Height_dist', 'Weight_dist',\n",
    "       '40 Yard Dash_dist', 'Vertical Jump_dist', 'Broad Jump_dist',\n",
    "       'Arm Length_dist']\n",
    "elif dist_setting == \"no dist\":\n",
    "    fit_features = ['Power 5','Height', 'Weight',\n",
    "           '40 Yard Dash', 'Vertical Jump', 'Broad Jump',\n",
    "           'Arm Length', 'rec', 'rec_yds', \"rec_td\"]\n",
    "elif dist_setting == \"only dist\":\n",
    "    fit_features = ['Power 5', 'rec', 'rec_yds', \"rec_td\", 'Height_dist', 'Weight_dist',\n",
    "       '40 Yard Dash_dist', 'Vertical Jump_dist', 'Broad Jump_dist',\n",
    "       'Arm Length_dist']\n",
    "else:\n",
    "    raise NameError(\"Fit feature list not defined\")\n",
    "\n",
    "#Now fit. We'll use different datasets to get a better grasp on the actual validation metrics of the model.\n",
    "#We'll also keep track of a bunch of diagnostic info.\n",
    "as_list = []\n",
    "precision_list = []\n",
    "good_as_bad = []\n",
    "bad_as_good = []\n",
    "total_good = []\n",
    "thresh = 0.95\n",
    "total_predicted = []\n",
    "for i in range(50):\n",
    "    #Split data into test/train sets\n",
    "    features_train, features_test, player_types_train, player_types_test = train_test_split(balanced_features[fit_features],\\\n",
    "                                                                                            player_types, test_size=0.33)\n",
    "    \n",
    "    #GBC works best for this data\n",
    "    clf = GradientBoostingClassifier(n_estimators=350, learning_rate=0.47)\n",
    "    clf.fit(features_train, player_types_train)\n",
    "    \n",
    "    #Get prediction probs\n",
    "    pred_probs = clf.predict_proba(features_test)\n",
    "    pred = clf.predict(features_test)\n",
    "    \n",
    "    #Get accuracy, precision, and confusion matrix\n",
    "    as_list.append(accuracy_score(predictions_with_threshold(pred_probs, thresh = thresh), player_types_test))\n",
    "    precision_list.append(precision_score(predictions_with_threshold(pred_probs, thresh = thresh), player_types_test))\n",
    "    cm = confusion_matrix(predictions_with_threshold(pred_probs, thresh = thresh), player_types_test)\n",
    "    \n",
    "    #Get interesting stats from the confusion matrix\n",
    "    total_good.append(sum(player_types_test))\n",
    "    total_predicted.append(sum(predictions_with_threshold(pred_probs, thresh = thresh), player_types_test))\n",
    "    good_as_bad.append(cm[0,1])\n",
    "    bad_as_good.append(cm[1,0])\n",
    "    \n",
    "#Print out useful metrics\n",
    "final_preds = predictions_with_threshold(pred_probs, thresh = thresh)\n",
    "print(\"Model accuracy:  %0.1f%s %0.1f\" % (np.average(as_list)*100, \"% +/-\", np.std(as_list)*100))\n",
    "print(\"Model precision: %0.1f%s %0.1f\" % (np.average(precision_list)*100, \"% +/-\", np.std(precision_list)*100))\n",
    "\n",
    "print(\"Number of WRs:                       \", len(player_types_test))\n",
    "print(\"Number of good WRs predicted:        \", np.average(total_predicted))\n",
    "print(\"True number of good WRs:             \", np.average(total_good))\n",
    "print(\"Number of good WRs classified as bad:\", np.average(good_as_bad))\n",
    "print(\"Number of bad WRs classified as good:\", np.average(bad_as_good))\n",
    "\n",
    "#Plot the confusion matrix\n",
    "plot_confusion_matrix(player_types_test, final_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's sort and plot the importances of all the features\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plot_labels = [x.replace(\"rec_td\", \"Touchdowns\").replace(\"rec_yds\", \"Yards\").replace(\"rec\",\"Receptions\") for x in fit_features ]\n",
    "n_features = len(indices)\n",
    "fig = plt.figure(figsize = [15,10])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(range(n_features), importances[indices], align=\"center\")\n",
    "plt.xticks(range(n_features), indices, rotation = 45, fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax.set_xticklabels(plot_labels)\n",
    "ax.xaxis.set_ticks_position(\"bottom\")\n",
    "plt.title(\"Classifier Feature Importances\", fontsize=20)\n",
    "plt.ylabel(\"Normalized Importance\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importances.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(n_features):\n",
    "    print(\"%d. %s (%0.2f)\" % (f + 1, fit_features[f], importances[indices[f]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's make predictions about the most recent draft class. This is what I'll use for the demo.\n",
    "stime = time.time()\n",
    "\n",
    "\n",
    "#Note that this will be messy since it's web scraping. Also it's really similar to the other scraping,\n",
    "#so I won't bother commenting this well.\n",
    "measurables = [\"height\", \"weight\", \"wingspan\", \"arms\", \"hands\", \"40yd\", \"bench\", \"vertical\", \"broad\", \"3cone\", \"20ss\"]\n",
    "needs_conversion = [\"wingspan\", \"arms\", \"hands\", \"vertical\", \"broad\"]\n",
    "\n",
    "corrections = {\n",
    "    \"r.jay soward\": \"r. jay soward\",\n",
    "    \"johnathan holland\":\"jonathan holland\",\n",
    "    \"terrance toliver\":\"terrence toliver\",\n",
    "    \"odell beckham jr.\" : \"odell beckham, jr.\",\n",
    "    \"mike campanaro\":\"michael campanaro\",\n",
    "    \"t.j.  jones\" : \"t.j. jones\",\n",
    "    \"chris  godwin\":\"chris godwin\",\n",
    "    \"dante pettis\":\"dante pettis \"\n",
    "}\n",
    "\n",
    "key_change = {\n",
    "        \"40yd\":\"40 Yard Dash\",\n",
    "        \"height\":\"Height\",\n",
    "        \"weight\":\"Weight\",\n",
    "        \"vertical\":\"Vertical Jump\",\n",
    "        \"bench\":\"Bench Press\",\n",
    "        \"broad\":\"Broad Jump\",\n",
    "        \"3cone\":\"3-Cone Drill\",\n",
    "        \"20ss\":\"20 Yard Shuttle\",\n",
    "        \"arms\":\"Arm Length\",\n",
    "        \"hands\":\"Hand Size\",\n",
    "        \"10yd\":\"10 Yard Split\",\n",
    "        \"wingspan\":\"Wingspan\"\n",
    "}\n",
    "\n",
    "unknown_combines_dict = {}\n",
    "\n",
    "for measurable in measurables:\n",
    "    print(\"Working on\", measurable, time.ctime().split()[-2])\n",
    "    alt_measurable = key_change[measurable]\n",
    "    j=1\n",
    "    for i in range(1,50):\n",
    "        try:\n",
    "            url = \"https://www.mockdraftable.com/search?position=ATH&beginYear=2019&endYear=2019&sort=DESC&page=\"+str(i)+\"&measurable=\" + measurable\n",
    "            html = urlopen(url)\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            for n, h in zip(soup.find_all(\"h5\"), soup.find_all(\"figure\")):\n",
    "                name = n.text.lower()\n",
    "                pos = soup.find_all(\"span\")[2*j].text\n",
    "                if name in corrections.keys():\n",
    "                    name = corrections[name]\n",
    "                if not name in unknown_combines_dict.keys():\n",
    "                    unknown_combines_dict[name] = {\"pos\":pos}\n",
    "                if not h.text == \"?\":\n",
    "                    if measurable == \"height\":\n",
    "                        unknown_combines_dict[name][alt_measurable] = height_string_to_cm(h.text)\n",
    "                    elif measurable in needs_conversion:\n",
    "                        val_string = h.text.replace(\"*\",\"\").replace(\"lbs\",\"\").replace(\"reps\",\"\").replace(\"s\",\"\")\n",
    "                        unknown_combines_dict[name][alt_measurable] = length_to_in(val_string)\n",
    "                    else:\n",
    "                        unknown_combines_dict[name][alt_measurable] = float(h.text.replace(\"*\",\"\").replace(\"lbs\",\"\").replace(\"reps\",\"\").replace(\"s\",\"\"))\n",
    "                j+=1\n",
    "        except ValueError:\n",
    "            break\n",
    "        \n",
    "        j=1\n",
    "\n",
    "\n",
    "print(\"Done in %0.2f minutes\" %((time.time()-stime)/60))\n",
    "bkp = deepcopy(unknown_combines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = time.time()\n",
    "unknown_combines = pd.DataFrame.from_dict(unknown_combines_dict, orient=\"index\")\n",
    "unknown_combines = unknown_combines[unknown_combines[\"pos\"] == \"WR\"]\n",
    "for name in unknown_combines.index.values:\n",
    "    useful_name = \"-\".join(name.replace(\".\",\"\").replace(\"'\",\"\").split())\n",
    "    url = \"https://www.sports-reference.com/cfb/players/\" + useful_name + \"-1.html\"\n",
    "    if name == \"felton davis\":\n",
    "        url = \"https://www.sports-reference.com/cfb/players/felton-davis-iii-1.html\"\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        unknown_combines_dict[name][\"years_played\"] = len(soup.find_all('tr'))-3\n",
    "        unknown_combines_dict[name]['school_name'] = soup.find_all('tr')[-2].find_all('td')[0].text\n",
    "        unknown_combines_dict[name]['position'] = soup.find_all('tr')[-2].find_all('td')[3].text\n",
    "        unknown_combines_dict[name]['conference'] = soup.find_all('tr')[-2].find_all('td')[1].text\n",
    "    except Exception as e:\n",
    "        print(url)\n",
    "        continue\n",
    "    gp = 0\n",
    "    for row in soup.find_all('tr')[2:-1]:\n",
    "        if row.find_all('th')[0].text.lower() == \"career\":\n",
    "            break\n",
    "        else:\n",
    "            grad_year = int(row.find_all('th')[0].text.replace(\"*\",\"\"))\n",
    "        for col in row.find_all('td'):\n",
    "            if col['data-stat'] == 'g':\n",
    "                if col.text == '':\n",
    "                    pass\n",
    "                else:\n",
    "                    gp += int(col.text)\n",
    "    unknown_combines_dict[name]['games_played'] = gp\n",
    "    unknown_combines_dict[name]['grad_year'] = grad_year\n",
    "    \n",
    "    # We only want the *career* stats for the college_player, so we only want to look at the\n",
    "    # last line of the table. That's why we're only looking at soup.find_all('tr')[-1].\n",
    "    # On that last line, we want skip the first column, since it's always a string that we\n",
    "    # don't care about, and trying to convert it to a float will cause an error. So we skip it\n",
    "    # by doing \".find_all('td')[1:]\". That's actually showing us the columns of that row.\n",
    "    # We'll call each column \"stat\", since it contains a statistic.\n",
    "    for stat in soup.find_all('tr')[-1].find_all('td')[1:]:\n",
    "        # In the table, missing stats are just empty strings, so if we find an empty string,\n",
    "        # we'll just make it a 0.\n",
    "        if stat.text == '':\n",
    "            num = 0\n",
    "        # Otherwise convert the value to a float.\n",
    "        else:\n",
    "            num = float(stat.text)\n",
    "        \n",
    "        # Each column is a dictionary object, where \"data-stat\" returns the name of the column\n",
    "        # (so like passing yards, tackles, and so on), and the \"text\" is the actual value.\n",
    "        # So we're making a dictionary of our own where the keys are the name of the stat,\n",
    "        # and the value for that key is the actual value of the stat.\n",
    "        unknown_combines_dict[name][stat['data-stat']] = num\n",
    "\n",
    "\n",
    "unknown_combines = pd.DataFrame.from_dict(unknown_combines_dict, orient=\"index\")\n",
    "unknown_combines = pd.concat([unknown_combines[(unknown_combines[\"pos\"] == 0)], unknown_combines[unknown_combines[\"pos\"] == \"WR\"]])\n",
    "unknown_combines[\"Power 5\"] = unknown_combines[\"conference\"].isin([\"ACC\", \"Big Ten\", \"Big 12\", \"SEC\", \"Pac12\"])**2\n",
    "print(\"Done in %0.2f minutes\" %((time.time()-stime)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll do the same type of filtering/scaling we did for the training data.\n",
    "unknown_combines_subset = unknown_combines[combine_features+ [\"rec\", \"rec_yds\", \"rec_td\"]]\n",
    "unknown_combines_mask = ~unknown_combines_subset.isnull().any(axis=1)\n",
    "pure_unknown_combines = unknown_combines[unknown_combines_mask.values]\n",
    "scaled_unknown_combines = pd.DataFrame(scaler.transform(pure_unknown_combines[combine_features + [\"rec\", \"rec_yds\", \"rec_td\"]]), columns=combine_features + [\"rec\", \"rec_yds\", \"rec_td\"])\n",
    "for feat in combine_features:\n",
    "    scaled_unknown_combines[feat + \"_dist\"] = (scaled_features[feat]**2)**0.5\n",
    "\n",
    "scaled_unknown_combines.insert(5, \"Power 5\", pure_unknown_combines[\"Power 5\"].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we actually do the prediction and look at the results.\n",
    "success_probs = [x[1] for x in clf.predict_proba(scaled_unknown_combines[fit_features])]\n",
    "names = pure_unknown_combines.index\n",
    "pred_list = [[y,x] for y,x in sorted(zip(success_probs,names), reverse = True)]\n",
    "\n",
    "for p in pred_list:\n",
    "    pr,n = p\n",
    "    print(\"['%s', %0.1f]\" % (n.title(),pr))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
